{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 5.0 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 KB ? eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.9.11-cp39-cp39-win_amd64.whl (274 kB)\n",
      "     -------------------------------------- 274.1/274.1 KB 8.5 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     -------------------------------------- 301.8/301.8 KB 9.4 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.9/97.9 KB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\hvall\\desktop\\workspace\\bcgxchallenge2024\\app\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.9.1 regex-2024.9.11 tqdm-4.66.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hvall\\Desktop\\workspace\\bcgxchallenge2024\\app\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# !pip install PyMuPDF\n",
    "# !pip install langchain-community\n",
    "# !pip install nltk\n",
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RUN THIS COMMAND JUST ONE TIME LOCALLY ########################################\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RUN THIS COMMAND JUST ONE TIME LOCALLY ########################################\n",
    "# !python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bronze to Silver0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_directory2(directory_path):\n",
    "    # List only files (not directories)\n",
    "    return [directory_path + file for file in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file))]\n",
    "\n",
    "def list_files_in_directory(directory_path):\n",
    "    # List only files (not directories)\n",
    "    return [file for file in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file))]\n",
    "\n",
    "def pdf_to_txt(file_name):\n",
    "    loader = PyMuPDFLoader(bronze_path + file_name)\n",
    "    # here we have a class with metadata\n",
    "    data = loader.load()\n",
    "\n",
    "    # this way we get all the text of the pdf in just 1 string\n",
    "    text = ''\n",
    "    for i in range(len(data)):\n",
    "        text = text + data[i].page_content\n",
    "\n",
    "    silver_path = f'../medallion/silver0/{file_name[:-4]}.txt'\n",
    "\n",
    "    with open(silver_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "def remove_accents_and_special_characters(file0):\n",
    "    # Open the file and read all the content\n",
    "    with open(file0, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Normalize the text to separate accents from letters\n",
    "    normalized_text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # Remove accents by discarding non-ASCII characters\n",
    "    text_without_accents = normalized_text.encode('ASCII', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Remove any special characters (keeping letters and numbers)\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text_without_accents)\n",
    "\n",
    "    # Convert the content to lowercase\n",
    "    clean_text = clean_text.lower()\n",
    "    \n",
    "    # Replace 'silver0' with 'silver1'\n",
    "    silver1_path = file0.replace('silver0', 'silver1')\n",
    "\n",
    "    # Open the file in write mode and write the string to it\n",
    "    with open(silver1_path, 'w') as file:\n",
    "        file.write(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hvall\\Desktop\\workspace\\bcgxchallenge2024\\app\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:299: UserWarning: Warning: Empty content on page 135 of document ../medallion/bronze/plano-acao-climatica-agro.pdf\n",
      "  warnings.warn(\n",
      "c:\\Users\\hvall\\Desktop\\workspace\\bcgxchallenge2024\\app\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:299: UserWarning: Warning: Empty content on page 83 of document ../medallion/bronze/plano-acao-climatica-itabirito.pdf\n",
      "  warnings.warn(\n",
      "c:\\Users\\hvall\\Desktop\\workspace\\bcgxchallenge2024\\app\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:299: UserWarning: Warning: Empty content on page 0 of document ../medallion/bronze/plano-acao-climatica-sp-regiao.pdf\n",
      "  warnings.warn(\n",
      "c:\\Users\\hvall\\Desktop\\workspace\\bcgxchallenge2024\\app\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:299: UserWarning: Warning: Empty content on page 133 of document ../medallion/bronze/plano-acao-climatica-sp-regiao.pdf\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# here we transfer from Bronze to Silver0\n",
    "bronze_path = '../medallion/bronze/'\n",
    "file_list = list_files_in_directory(bronze_path)\n",
    "\n",
    "for file in file_list:\n",
    "    pdf_to_txt(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silver0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../medallion/silver0/plano-acao-adaptacao-climatica-nacional.txt',\n",
       " '../medallion/silver0/plano-acao-climatica-agro.txt',\n",
       " '../medallion/silver0/plano-acao-climatica-curitiba.txt',\n",
       " '../medallion/silver0/plano-acao-climatica-federal.txt',\n",
       " '../medallion/silver0/plano-acao-climatica-itabirito.txt',\n",
       " '../medallion/silver0/plano-acao-climatica-joao-pessoa.txt',\n",
       " '../medallion/silver0/plano-acao-climatica-sp-regiao.txt',\n",
       " '../medallion/silver0/plano-enfrentamento-mudanca-climatica-nacional.txt']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver0_path = '../medallion/silver0/'\n",
    "list_files_in_directory2(silver0_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_convert_to_lowercase(filename):\n",
    "    # Open the file in read mode with UTF-8 encoding\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Convert the content to lowercase\n",
    "    lowercase_content = content.lower()\n",
    "    \n",
    "    return lowercase_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silver 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../medallion/silver0/plano-acao-adaptacao-climatica-nacional.txt\n",
      "../medallion/silver0/plano-acao-climatica-agro.txt\n",
      "../medallion/silver0/plano-acao-climatica-curitiba.txt\n",
      "../medallion/silver0/plano-acao-climatica-federal.txt\n",
      "../medallion/silver0/plano-acao-climatica-itabirito.txt\n",
      "../medallion/silver0/plano-acao-climatica-joao-pessoa.txt\n",
      "../medallion/silver0/plano-acao-climatica-sp-regiao.txt\n",
      "../medallion/silver0/plano-enfrentamento-mudanca-climatica-nacional.txt\n"
     ]
    }
   ],
   "source": [
    "silver0_path = '../medallion/silver0/'\n",
    "file_list = list_files_in_directory2(silver0_path)\n",
    "\n",
    "for file0 in file_list:\n",
    "    remove_accents_and_special_characters(file0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silver 2: stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(file0):\n",
    "\n",
    "    # Open the file and read all the content\n",
    "    with open(file0, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Get the list of Portuguese stopwords\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "    # Split the string into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_text = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Join the filtered words back into a string\n",
    "    result = ' '.join(filtered_text)\n",
    "\n",
    "    # Replace 'silver0' with 'silver1'\n",
    "    silver2_path = file0.replace('silver1', 'silver2')\n",
    "\n",
    "    # Open the file in write mode and write the string to it\n",
    "    with open(silver2_path, 'w') as file:\n",
    "        file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver1_path = '../medallion/silver1/'\n",
    "file_list = list_files_in_directory2(silver1_path)\n",
    "\n",
    "for file0 in file_list:\n",
    "    remove_stopwords(file0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silver 3: Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(file0):\n",
    "    # Open the file and read all the content\n",
    "    with open(file0, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "    # Process the text with the spaCy NLP model\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract the lemmatized tokens\n",
    "    lemmatized_text = ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "    # Replace 'silver0' with 'silver1'\n",
    "    silver2_path = file0.replace('silver2', 'silver3')\n",
    "\n",
    "    # Open the file in write mode and write the string to it\n",
    "    with open(silver2_path, 'w') as file:\n",
    "        file.write(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver2_path = '../medallion/silver2/'\n",
    "file_list = list_files_in_directory2(silver2_path)\n",
    "\n",
    "for file0 in file_list:\n",
    "    remove_stopwords(file0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tresnove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
